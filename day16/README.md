#### [回目錄](../README.md)
## Day16 selenium-webdriver：優化爬蟲體驗 & 思路分享

🤔 為什麼寫這篇文章
----
1. 如果你跟著這幾天的教學走還是遇到一些莫名其妙的問題，希望在今天的文章有得到你想要的解答
2. 這幾天所教的技巧足以讓你爬下絕大多數的網頁資訊了，`學習爬蟲只是一個過程，我們的目標是希望能靠這些數據給我們帶來便利`，所以今天也分享一些思路給大家

🏆 今日目標
----
### 1. 優化爬蟲
1.1 優化分成哪些面向?
1.2 優化執行效率及穩定度
1.3 背景執行並減少記憶體的消耗

### 2. 分享技術延伸思路

# 1. 優化爬蟲
昨天我們已經完成爬蟲所需要的功能了，下一步要思考的是如何優化
### 1.1 優化分成哪些面向?
前面[Day13 重構程式碼](../day13/README.md)在討論讓你開發上更有效率的要點，原則上不會影響到輸出的結果；而今天討論的優化是一個多面向的問題，我把他區分成顯性及隱性兩種：
* **顯性**：使用者一看就知道的改變
    * 改善使用者操作流程、介面
    * 程式執行過程的畫面調整
* **隱性**：使用者可能無感的改變
    * 更好地執行效率
    * 使用更少的記憶體  
    * 執行的穩定性

優化是一條沒有盡頭的路，上面我只是提了幾個常見要注意的點而已，接下來我們就來實際優化現在的爬蟲吧～  

### 1.2  優化執行效率及穩定度
* **遇到的問題**
    1. 在driver.wait加上等待時間後偶爾還是會出現登入失敗或是抓不到追蹤人數的問題
    2. 在爬蟲的時候會影響到我看youtube的流暢程度
* **判斷造成的原因**
    1. 本身的網路速度太慢，造成網頁過了driver.wait的等待時間後依舊還沒完成載入 
    2. FB、IG粉專都是充滿圖片的頁面，在載入這些資源時消耗太多流量
* **優化的方式**
    我們`爬蟲所分析的內容都跟圖片無關，所以只要不載入這些資源`就有以下好處：
    1. 減少瀏覽器使用流量
    2. 減少瀏覽器載入時間  

    想要知道如何不載入圖片，你可以在Google搜尋 **selenium chrome參數** ，有很多熱心的大神已經幫你整理好常用的參數了  
    * 打開 **initDrive.js** 在chrome的option加入`不載入圖片`的參數
        ```js
        options.addArguments('blink-settings=imagesEnabled=false')//不加載圖片提高效率
        ```
        加上這段程式後，在專案資料夾的終端機(Terminal)執行指令 **yarn start** ，便可以很明顯的感受到`網頁載入速度變快很多，並且所有圖片都沒有載入`(下圖)  
        ![image](./article_img/no_img.png)  

### 1.3 背景執行並減少記憶體的消耗
* **遇到的問題**
    1. 有時爬蟲執行到一半手賤點一下爬蟲瀏覽器導致程式拋出例外
    2. 爬蟲執行時候的畫面一直閃好煩
    3. 在記憶體8G的電腦執行爬蟲時覺得電腦變得很頓
* **判斷造成的原因**
    1. 人有時控制不住自己的手
    2. 執行爬蟲時干擾到使用者的日常工作    
    3. chrome吃的記憶體太多
* **優化的方式**  
    在每個爬蟲的步驟及功能都很穩定後，其實不需要跳出瀏覽器視窗來看他的動作，`讓瀏覽器在背景執行不但不會干擾使用者工作更能減少記憶體的浪費`
    * 打開 **initDrive.js** 並在chrome的option加入`不打開瀏覽器視窗`的參數如下
        ```js
        options.addArguments('--headless')//瀏覽器不提供頁面觀看，linux下如果系統是純文字介面不加這條會啓動失敗
        options.addArguments('--log-level=3')//這個option可以讓你跟headless時網頁端的console.log說掰掰
        //下面參數能提升爬蟲穩定性    
        options.addArguments('--disable-dev-shm-usage')//使用共享內存RAM
        options.addArguments('--disable-gpu')//規避部分chrome gpu bug
        ```
        設定完這些後，在專案資料夾的終端機(Terminal)執行指令 **yarn start** ，是不是就不會跳出瀏覽器、電腦也比較順暢了呢?     

----

# 2. 分享技術延伸思路
>**授人以魚不如授人以漁**  
使用模擬瀏覽器來爬蟲我認為是最符合初學者的，你不用去分析複雜的api，去猜裡面的參數是甚麼意義  
你需要做的只是把你平常操作的流程用程式的方式來替你做一遍，然後抓取你所需要的資訊  
我寫的文章只是爬蟲的技巧的冰山一角，但只要有了開頭以及研究的方向我相信你是有能力獨立完成其他網頁的爬蟲  

現在人工智慧流行，大數據當道，爬蟲是取得大數據的方法之一，你能透過這些數據分析的東西太多了，我在這裡簡單舉例：
* **追蹤人數爆減/爆增**
    * 是因為某一篇貼文引起的嗎?
    * 當天是否有媒體新聞的報導?
    * 粉專經營者是否有特殊決策?
* **發文頻率與追蹤人數的關係**
    * 發文頻率是否與追蹤人數成長正相關
    * 怎麼樣的發文頻率是最恰當的
    * 不同行業的發文頻率比較
* **貼文按讚與回應**
    * 什麼樣的貼文會獲得最多迴響
    * 獲得最多讚的貼文有什麼共同特徵  

透過數據你能夠做到的事情實在太多了，每一個獨立出來都能成為一篇論文或是商品，`爬蟲是一個很強的武器，但這把武器的強度要看使用者如何發揮他`  

*再次提醒，技術沒有善惡，人的使用方式才會有善惡，希望這份技術可以幫大家節省時間以及避免重工；如果你把它拿來盜取智慧財產、個人檔案及機敏資訊請自行負擔後續法律責任*

----

>**筆者碎碎念**  
我希望看完文章的讀者能夠吸收到思考問題的方式，不要只是單純的 copy & paste ，這樣對技術長期來講是在累積負債  
如果你是程式的新手，你可以透過修改一些參數來看看結果會有什麼樣的變化，少加哪些參數是不是真的會有錯誤  
不要害怕犯錯，因為在學習程式的路上幾乎不存在一條完美的道路  
你現在滿意的程式往往在幾個月後你會覺得當時怎麼寫的這麼爛  
當你誕生出這個想法的時候就是成長了  

⏭️ 下個階段
----
關於使用網頁爬蟲的技術文章就分享到今天，接下來我們要來研究 `爬蟲下來的資訊如何儲存` ，敬請期待

ℹ️ 專案原始碼
----
* 今天的完整程式碼可以在[這裡](https://github.com/dean9703111/ithelp_30days/tree/master/day16)找到喔
* 我也貼心地把昨天的把昨天的程式碼打包成[壓縮檔](https://github.com/dean9703111/ithelp_30days/raw/master/sampleCode/day15_sample_code.zip)，你可以用裡面乾淨的環境來實作今天json改寫的部分喔
    * 請記得在終端機下指令 **yarn** 才會把之前的套件安裝
    * 調整.env檔
        * 填上FB登入資訊
        * 填上FB版本(classic/new)
        * 填上IG登入資訊
    * 調整fanspages資料夾內目標爬蟲的粉專網址

📖 參考資源
----
1. [selenium啓動Chrome的進階配置參數](https://stackoverflow.max-everyday.com/2019/12/selenium-chrome-options/)
<br>

>*免責聲明:文章技術僅抓取公開數據作爲研究，任何組織和個人不得以此技術盜取他人智慧財產、造成網站損害，否則一切后果由該組織或個人承擔。作者不承擔任何法律及連帶責任！*
### [Day17 Google Sheets-起手式，取得寫入Google Sheets的憑證(credentials)](/day17/README.md)